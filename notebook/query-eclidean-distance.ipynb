{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas tiktoken openai numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/amrish_kushwaha/Desktop/workspace/k8s-cost-clinder/notebook/aws.csv\")\n",
    "df = df.dropna()\n",
    "df = df[[\"vendor\",\"instance_type\",\"vcpu\",\"memory_gib\",\"cost_in_dollars\"]]\n",
    "df[\"summarized\"] = (\"vendor: \" + df.vendor.str.strip() + \"; instance_type: \" +   df.instance_type.str.strip()  + \"; vcpu: \" + df.vcpu.map(str) + \"; memory_gib: \" +  df.memory_gib.map(str) +  \"; cost_in_dollars: \" + df.cost_in_dollars.map(str))\n",
    "df[\"token\"] = df.summarized.apply(lambda x:len(encoding.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor</th>\n",
       "      <th>instance_type</th>\n",
       "      <th>vcpu</th>\n",
       "      <th>memory_gib</th>\n",
       "      <th>cost_in_dollars</th>\n",
       "      <th>summarized</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AWS</td>\n",
       "      <td>m6i.24xlarge</td>\n",
       "      <td>96</td>\n",
       "      <td>384 GiB</td>\n",
       "      <td>5.760</td>\n",
       "      <td>vendor: AWS; instance_type: m6i.24xlarge; vcpu...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AWS</td>\n",
       "      <td>u-12tb1.112xlarge</td>\n",
       "      <td>448</td>\n",
       "      <td>12288 GiB</td>\n",
       "      <td>185.493</td>\n",
       "      <td>vendor: AWS; instance_type: u-12tb1.112xlarge;...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AWS</td>\n",
       "      <td>m5d.8xlarge</td>\n",
       "      <td>32</td>\n",
       "      <td>128 GiB</td>\n",
       "      <td>14.336</td>\n",
       "      <td>vendor: AWS; instance_type: m5d.8xlarge; vcpu:...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWS</td>\n",
       "      <td>r5n.12xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>384 GiB</td>\n",
       "      <td>22.344</td>\n",
       "      <td>vendor: AWS; instance_type: r5n.12xlarge; vcpu...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWS</td>\n",
       "      <td>m5.16xlarge</td>\n",
       "      <td>64</td>\n",
       "      <td>256 GiB</td>\n",
       "      <td>11.520</td>\n",
       "      <td>vendor: AWS; instance_type: m5.16xlarge; vcpu:...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor      instance_type  vcpu memory_gib  cost_in_dollars  \\\n",
       "0    AWS       m6i.24xlarge    96    384 GiB            5.760   \n",
       "1    AWS  u-12tb1.112xlarge   448  12288 GiB          185.493   \n",
       "2    AWS        m5d.8xlarge    32    128 GiB           14.336   \n",
       "3    AWS       r5n.12xlarge    48    384 GiB           22.344   \n",
       "4    AWS        m5.16xlarge    64    256 GiB           11.520   \n",
       "\n",
       "                                          summarized  token  \n",
       "0  vendor: AWS; instance_type: m6i.24xlarge; vcpu...     40  \n",
       "1  vendor: AWS; instance_type: u-12tb1.112xlarge;...     43  \n",
       "2  vendor: AWS; instance_type: m5d.8xlarge; vcpu:...     40  \n",
       "3  vendor: AWS; instance_type: r5n.12xlarge; vcpu...     40  \n",
       "4  vendor: AWS; instance_type: m5.16xlarge; vcpu:...     39  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text, embeddding_mode=\"text-embedding-ada-002\"):\n",
    "    result = openai.Embedding.create(model=embeddding_mode, input=text)\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_df_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    return { idx: get_text_embedding(r.summarized) for idx, r in df.iterrows()}\n",
    "\n",
    "document_embeddings = get_df_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    return euclidean(np.array(x), np.array(y))\n",
    "\n",
    "def get_docs_with_similarity(query: str, df_embedding: dict[(str, str), np.array]) -> list[float, (str, str)]:\n",
    "    query_embedding = get_text_embedding(query)\n",
    "    document_similarities = sorted([(calculate_vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in df_embedding.items()], reverse=True)\n",
    "    return document_similarities\n",
    "\n",
    "# get_docs_with_similarity(\"Which instance_type is costliest\", document_embeddings)[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "separator_len = len(encoding.encode(\"\\n* \"))\n",
    "\n",
    "def create_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    relevant_document_sections = get_docs_with_similarity(question, context_embeddings)\n",
    "\n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "\n",
    "    for _, section_index in relevant_document_sections:\n",
    "        document_section = df.loc[section_index]\n",
    "        chosen_sections_len += document_section.token + separator_len\n",
    "        if chosen_sections_len > 500:\n",
    "            break\n",
    "\n",
    "        chosen_sections.append(\"\\n* \" + document_section.summarized.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "\n",
    "    header = \"\"\"    \n",
    "    You are a data analyst answering the questions using the CSV data you have. When asked for cost effective instance_type by providing a \n",
    "    vCPU value and Memory in GiB in the question, Go and check for all the instances which vCPU value is equal to or greater than the provided\n",
    "    vCPU value as well as which Memory in GiB value is equal to or greater than the provided Memory in GiB value. After than filter that instance\n",
    "    type which cost is lowest and return corresponding instance type and cost values. If you can only find one instance type, then return corresponding\n",
    "    instance type and cost values.\n",
    "    \n",
    "    If you are not able to find any instance types, return I don't know.\n",
    "\n",
    "    If you don't know the anwaser to a question or if it completely irrelevant to the data, simply reply with 'I don't know',\n",
    "\n",
    "    Now answer the follow question:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query: str, df: pd.DataFrame, document_embeddings: dict[(str, str), np.array]) -> str:\n",
    "    prompt = create_prompt(query, document_embeddings, df)\n",
    "    \n",
    "    response = openai.Completion.create(prompt=prompt, temperature=0, max_tokens=500, model=\"text-davinci-003\")\n",
    "    return response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: Please suggest the most cost-effective instance_type that satisfies the following both conditions: vcpu is 20, and memory_gib is 400. How many instances are required?\n",
      "A: The most cost-effective instance_type that satisfies the conditions of vCPU is 20 and Memory in GiB is 400 is c5.2xlarge with a cost of $3.936. You would need 1 instance.\n"
     ]
    }
   ],
   "source": [
    "query = \"Please suggest the most cost-effective instance_type that satisfies the following both conditions: vcpu is 20, and memory_gib is 400. How many instances are required?\"\n",
    "response = get_answer(query, df, document_embeddings)\n",
    "print(f\"\\nQ: {query}\\nA:{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: Please suggest the costliest instance type irrespective of vcpu and memory value\n",
      "A: The costliest instance type is n1-highmem-16 from GCP with a cost of 0.9472 dollars.\n"
     ]
    }
   ],
   "source": [
    "query = \"Please suggest the costliest instance type irrespective of vcpu and memory value\"\n",
    "response = get_answer(query, df, document_embeddings)\n",
    "print(f\"\\nQ: {query}\\nA:{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: Give me all instance types that have vcpu >= 10\n",
      "A: c5a.2xlarge, c5.metal, m3.2xlarge, c5.9xlarge, c5d.18xlarge, u-12tb1.112xlarge, m5.16xlarge, i4i.2xlarge, c5n.2xlarge.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me all instance types that have vcpu >= 10\"\n",
    "response = get_answer(query, df, document_embeddings)\n",
    "print(f\"\\nQ: {query}\\nA:{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: Give me one cost-effective instance_type with 5 or more vcpu\n",
      "A: The most cost-effective instance_type with 5 or more vcpu is m5.xlarge with 4 vcpu and 16 GiB memory at a cost of $0.192 per hour. If you need 5 vcpu, you can use two m5.xlarge instances for a total cost of $0.384 per hour.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me one cost-effective instance_type with 5 or more vcpu\"\n",
    "response = get_answer(query, df, document_embeddings)\n",
    "print(f\"\\nQ: {query}\\nA:{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
